{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9CqHuRi5lrPJC5mqs4O4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3be0a0e87a0143cdbcab2cc836a44242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8fa30c4b3a246d1b87478915e91afbc",
              "IPY_MODEL_07e539549fa14d038f17de147d5860ec"
            ],
            "layout": "IPY_MODEL_e7e840c8861c46c4a3f42902a20db0a7"
          }
        },
        "d8fa30c4b3a246d1b87478915e91afbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cb65fe6a37426ca4360d73aa2d84f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7aa2f3e7af204082a30e2a741f88e920",
            "value": "13.812 MB of 13.812 MB uploaded\r"
          }
        },
        "07e539549fa14d038f17de147d5860ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42651792c138492c9a0e6bb1413d79e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3222d42ae01c45aba050929f8d0ec04e",
            "value": 1
          }
        },
        "e7e840c8861c46c4a3f42902a20db0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cb65fe6a37426ca4360d73aa2d84f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa2f3e7af204082a30e2a741f88e920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42651792c138492c9a0e6bb1413d79e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3222d42ae01c45aba050929f8d0ec04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitanyasinghnegi/License_plate_detection/blob/main/License_plate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdNiOZ3LdEu4",
        "outputId": "c3743cde-d205-4f6c-a714-25c61e3090e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.22-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.22-py3-none-any.whl (877 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m877.5/877.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.22 ultralytics-thop-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"3vjVSWx2veuwHXa2MEEb\")\n",
        "project = rf.workspace(\"mochoye\").project(\"license-plate-detector-ogxxg\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQgji0NydyRg",
        "outputId": "f4fa9b0e-97a6-4476-9c85-eddaf53a031a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.48-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.48-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.48\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in License-Plate-Detector-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20648/20648 [00:00<00:00, 33153.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to License-Plate-Detector-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 802/802 [00:00<00:00, 7075.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=\"/content/License-Plate-Detector-2/data.yaml\", epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3be0a0e87a0143cdbcab2cc836a44242",
            "d8fa30c4b3a246d1b87478915e91afbc",
            "07e539549fa14d038f17de147d5860ec",
            "e7e840c8861c46c4a3f42902a20db0a7",
            "69cb65fe6a37426ca4360d73aa2d84f1",
            "7aa2f3e7af204082a30e2a741f88e920",
            "42651792c138492c9a0e6bb1413d79e8",
            "3222d42ae01c45aba050929f8d0ec04e"
          ]
        },
        "id": "iQml04n8dLOh",
        "outputId": "affe9ccc-7e69-40cd-f5ab-a47dfff985d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.22 üöÄ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/License-Plate-Detector-2/data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 24.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_093009-0o8aa887</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/craftercheeky-self/Ultralytics/runs/0o8aa887' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/craftercheeky-self/Ultralytics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/craftercheeky-self/Ultralytics' target=\"_blank\">https://wandb.ai/craftercheeky-self/Ultralytics</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/craftercheeky-self/Ultralytics/runs/0o8aa887' target=\"_blank\">https://wandb.ai/craftercheeky-self/Ultralytics/runs/0o8aa887</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 88.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/License-Plate-Detector-2/train/labels... 277 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [00:00<00:00, 1863.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/License-Plate-Detector-2/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/License-Plate-Detector-2/valid/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:00<00:00, 1492.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/License-Plate-Detector-2/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/25      2.24G      3.949       4.98      4.371          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:07<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81   0.000288     0.0864   0.000157   3.75e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/25       2.2G      3.868      4.538       4.12         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81   0.000329     0.0988   0.000182    5.4e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/25      2.21G      3.391      4.054       3.79         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81   0.000329     0.0988   0.000191   5.23e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/25      2.21G          3      3.507      3.456         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81   0.000453      0.136   0.000276   7.31e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/25      2.21G      3.063      3.201       3.39          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81   0.000198     0.0247   0.000108    2.1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/25      2.21G      2.801      3.029      3.247          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.102     0.0741      0.046     0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/25      2.21G      2.821      3.029      3.109          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.335      0.309      0.263     0.0867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/25      2.21G      2.673      2.729      3.054         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.213      0.222      0.155     0.0496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/25      2.21G      2.638      2.635      2.955          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.346      0.432      0.349     0.0971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/25      2.21G      2.649      2.492      2.963         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.343      0.355      0.276     0.0924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/25      2.21G      2.534      2.425      2.888          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.364      0.494      0.385      0.147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/25      2.21G       2.49      2.378      2.882          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.425      0.407      0.393      0.148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/25      2.21G      2.292      2.142      2.796          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.205      0.439      0.216     0.0805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/25      2.21G      2.303      2.045       2.71         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81       0.68      0.346      0.496      0.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/25      2.21G      2.251      2.008      2.708          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.682      0.423      0.581      0.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/25      2.21G      2.112      2.032      2.638          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:08<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.542      0.654      0.628      0.299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/25      2.21G      1.977      1.864      2.529          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.626      0.481       0.59      0.302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/25      2.21G      1.949      1.829       2.48          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81       0.56      0.568      0.614      0.265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/25      2.21G      1.945      1.723      2.469          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.864      0.691       0.83      0.418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/25      2.21G      1.871      1.729      2.455          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.801      0.746      0.844      0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/25      2.21G      1.806      1.624      2.399          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.767      0.753      0.824      0.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/25      2.21G      1.762       1.58      2.375          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.779      0.827      0.867      0.473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/25      2.21G      1.774       1.52      2.336          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.947      0.778      0.906      0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/25      2.21G       1.69      1.549      2.339          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.787      0.802      0.881      0.534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/25      2.21G      1.693      1.468      2.328          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.906       0.79      0.906      0.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "25 epochs completed in 0.052 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "WARNING ‚ö†Ô∏è validating an untrained model YAML will result in 0 mAP.\n",
            "Ultralytics 8.3.22 üöÄ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         81         81      0.906       0.79      0.905       0.56\n",
            "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='13.812 MB of 13.812 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be0a0e87a0143cdbcab2cc836a44242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>metrics/mAP50(B)</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/mAP50-95(B)</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>metrics/precision(B)</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà</td></tr><tr><td>metrics/recall(B)</td><td>‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/box_loss</td><td>‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/cls_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/dfl_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/box_loss</td><td>‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/cls_loss</td><td>‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/dfl_loss</td><td>‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0001</td></tr><tr><td>lr/pg1</td><td>0.0001</td></tr><tr><td>lr/pg2</td><td>0.0001</td></tr><tr><td>metrics/mAP50(B)</td><td>0.9053</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.55998</td></tr><tr><td>metrics/precision(B)</td><td>0.90636</td></tr><tr><td>metrics/recall(B)</td><td>0.79012</td></tr><tr><td>model/GFLOPs</td><td>8.194</td></tr><tr><td>model/parameters</td><td>3011043</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>7.298</td></tr><tr><td>train/box_loss</td><td>1.69271</td></tr><tr><td>train/cls_loss</td><td>1.46823</td></tr><tr><td>train/dfl_loss</td><td>2.32791</td></tr><tr><td>val/box_loss</td><td>1.57199</td></tr><tr><td>val/cls_loss</td><td>1.18644</td></tr><tr><td>val/dfl_loss</td><td>2.243</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/craftercheeky-self/Ultralytics/runs/0o8aa887' target=\"_blank\">https://wandb.ai/craftercheeky-self/Ultralytics/runs/0o8aa887</a><br/> View project at: <a href='https://wandb.ai/craftercheeky-self/Ultralytics' target=\"_blank\">https://wandb.ai/craftercheeky-self/Ultralytics</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 24 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_093009-0o8aa887/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5G2X-FVCKaF",
        "outputId": "e14aa7e6-62dc-4175-8068-ee5eb03f86bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/computervisioneng/automatic-number-plate-recognition-python-yolov8.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otQsKRh_EiRu",
        "outputId": "a2c017f4-b586-4601-a1eb-9c6970f5d5a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'automatic-number-plate-recognition-python-yolov8'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 55 (delta 27), reused 17 (delta 17), pack-reused 20 (from 1)\u001b[K\n",
            "Receiving objects: 100% (55/55), 7.00 MiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd automatic-number-plate-recognition-python-yolov8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "124MTgACGHz6",
        "outputId": "3d482ba9-741f-4abe-df77-1b0f8ce5c78a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automatic-number-plate-recognition-python-yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cXYn6kaaGMNJ",
        "outputId": "6490ce21-68df-4e52-feb5-917c4f4012ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.114 (from -r requirements.txt (line 1))\n",
            "  Downloading ultralytics-8.0.114-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting pandas==2.0.2 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting opencv-python==4.7.0.72 (from -r requirements.txt (line 3))\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scipy==1.10.1 (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easyocr==1.7.0 (from -r requirements.txt (line 6))\n",
            "  Downloading easyocr-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filterpy==1.4.5 (from -r requirements.txt (line 7))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.114->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr==1.7.0->-r requirements.txt (line 6)) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr==1.7.0->-r requirements.txt (line 6)) (0.24.0)\n",
            "Collecting python-bidi (from easyocr==1.7.0->-r requirements.txt (line 6))\n",
            "  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr==1.7.0->-r requirements.txt (line 6)) (2.0.6)\n",
            "Collecting pyclipper (from easyocr==1.7.0->-r requirements.txt (line 6))\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr==1.7.0->-r requirements.txt (line 6))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.2->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.7.0->-r requirements.txt (line 6)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.7.0->-r requirements.txt (line 6)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.7.0->-r requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics==8.0.114->-r requirements.txt (line 1)) (3.0.2)\n",
            "Downloading ultralytics-8.0.114-py3-none-any.whl (595 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m595.4/595.4 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easyocr-1.7.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=97edc68f367d26e8a4f321a0f65a631067c1350fb9eab65de828ecef9bc9a66d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: python-bidi, pyclipper, ninja, numpy, scipy, pandas, opencv-python, filterpy, easyocr, ultralytics\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.3.22\n",
            "    Uninstalling ultralytics-8.3.22:\n",
            "      Successfully uninstalled ultralytics-8.3.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.2 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.2 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.2 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed easyocr-1.7.0 filterpy-1.4.5 ninja-1.11.1.1 numpy-1.24.3 opencv-python-4.7.0.72 pandas-2.0.2 pyclipper-1.3.0.post6 python-bidi-0.6.3 scipy-1.10.1 ultralytics-8.0.114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2d30eed51b9a4e658b5f012cf5618e2e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/automatic-number-plate-recognition-python-yolov8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOJ8sMTvGeLl",
        "outputId": "642ecb9f-61b2-4fb6-b23b-a9bd2ffa198f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automatic-number-plate-recognition-python-yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abewley/sort.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnKAULc8Ghdt",
        "outputId": "c908ba12-83bf-4315-aaab-aa9c45d73332"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sort'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 208 (delta 2), reused 2 (delta 1), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (208/208), 1.21 MiB | 3.65 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.3.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "dWQ98kP1JPDH",
        "outputId": "2fb21fec-c738-4388-c470-34dac220053d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.3.22\n",
            "  Using cached ultralytics-8.3.22-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (1.24.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (4.7.0.72)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (2.0.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.22) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.22) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.22) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.22) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.22) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.22) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.22) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.22) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.22) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.22) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.22) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.22) (3.0.2)\n",
            "Using cached ultralytics-8.3.22-py3-none-any.whl (877 kB)\n",
            "Installing collected packages: ultralytics\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.0.114\n",
            "    Uninstalling ultralytics-8.0.114:\n",
            "      Successfully uninstalled ultralytics-8.0.114\n",
            "Successfully installed ultralytics-8.3.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ultralytics"
                ]
              },
              "id": "f327b19a5ab347b3bdff063f0c1734af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd automatic-number-plate-recognition-python-yolov8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shb2wCl4JaDT",
        "outputId": "6ed49e80-19ea-4bbe-c894-a066b62f3be7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automatic-number-plate-recognition-python-yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Kd7SkAGlgT",
        "outputId": "6c5c91d1-e82b-4c9b-92b4-25d6dbec949c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 2 trucks, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 1 truck, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25 cars, 1 truck, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 1 truck, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 1 bus, 1 truck, 23.5ms\n",
            "Speed: 2.7ms preprocess, 23.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 1 truck, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 truck, 8.3ms\n",
            "Speed: 13.6ms preprocess, 8.3ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 3 trucks, 31.7ms\n",
            "Speed: 2.6ms preprocess, 31.7ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 1 truck, 15.3ms\n",
            "Speed: 9.6ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 3 trucks, 28.3ms\n",
            "Speed: 8.7ms preprocess, 28.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 1 truck, 14.6ms\n",
            "Speed: 13.9ms preprocess, 14.6ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 2 trucks, 13.3ms\n",
            "Speed: 3.8ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 bus, 1 truck, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 3 trucks, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 29 cars, 2 trucks, 14.2ms\n",
            "Speed: 3.3ms preprocess, 14.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 3 trucks, 19.5ms\n",
            "Speed: 2.6ms preprocess, 19.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27 cars, 2 trucks, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 3 trucks, 17.7ms\n",
            "Speed: 2.7ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 2 trucks, 10.8ms\n",
            "Speed: 5.9ms preprocess, 10.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 3 trucks, 22.4ms\n",
            "Speed: 5.4ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 15.0ms\n",
            "Speed: 2.7ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 3 trucks, 27.1ms\n",
            "Speed: 5.7ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25 cars, 1 bus, 2 trucks, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 4 trucks, 23.3ms\n",
            "Speed: 2.7ms preprocess, 23.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 4 trucks, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 4 trucks, 36.0ms\n",
            "Speed: 2.7ms preprocess, 36.0ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 1 truck, 19.9ms\n",
            "Speed: 2.8ms preprocess, 19.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 4 trucks, 29.8ms\n",
            "Speed: 9.0ms preprocess, 29.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.5ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 1 bus, 4 trucks, 19.4ms\n",
            "Speed: 2.6ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 2 trucks, 16.8ms\n",
            "Speed: 2.8ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 4 trucks, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27 cars, 2 trucks, 18.4ms\n",
            "Speed: 9.7ms preprocess, 18.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 4 trucks, 32.4ms\n",
            "Speed: 7.7ms preprocess, 32.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 2 trucks, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 3 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.3ms\n",
            "Speed: 3.5ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 3 trucks, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 3 trucks, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 3 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 1 bus, 2 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 4 trucks, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 3 trucks, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 9.9ms\n",
            "Speed: 4.6ms preprocess, 9.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 3 trucks, 18.3ms\n",
            "Speed: 6.0ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 4 trucks, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25 cars, 1 truck, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 4 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 1 truck, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 bus, 3 trucks, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 1 truck, 21.8ms\n",
            "Speed: 5.8ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 3 trucks, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 4 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 12.4ms\n",
            "Speed: 2.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 2 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 bus, 1 truck, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 bus, 2 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 2 trucks, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 20.8ms\n",
            "Speed: 8.2ms preprocess, 20.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 3 trucks, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 cars, 1 truck, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 16.4ms\n",
            "Speed: 3.3ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 14.1ms\n",
            "Speed: 5.0ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 cars, 1 truck, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 13.7ms\n",
            "Speed: 3.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 17.6ms\n",
            "Speed: 2.8ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 12.4ms\n",
            "Speed: 2.8ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 11.6ms\n",
            "Speed: 4.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.5ms\n",
            "Speed: 4.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.5ms\n",
            "Speed: 6.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 17.8ms\n",
            "Speed: 5.1ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 bus, 1 truck, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 bus, 1 truck, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 17.0ms\n",
            "Speed: 7.1ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 36.4ms\n",
            "Speed: 10.6ms preprocess, 36.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 2 trucks, 21.0ms\n",
            "Speed: 9.8ms preprocess, 21.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 1 truck, 23.0ms\n",
            "Speed: 2.9ms preprocess, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 24.7ms\n",
            "Speed: 3.0ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 1 truck, 21.4ms\n",
            "Speed: 2.8ms preprocess, 21.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 14.3ms\n",
            "Speed: 4.2ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 1 truck, 20.6ms\n",
            "Speed: 2.8ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 41.3ms\n",
            "Speed: 2.6ms preprocess, 41.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 11.0ms\n",
            "Speed: 11.0ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 25.5ms\n",
            "Speed: 2.8ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 15.2ms\n",
            "Speed: 6.7ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 18.8ms\n",
            "Speed: 2.8ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 23.2ms\n",
            "Speed: 2.7ms preprocess, 23.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 18.3ms\n",
            "Speed: 2.7ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 20.4ms\n",
            "Speed: 10.1ms preprocess, 20.4ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 32.9ms\n",
            "Speed: 2.8ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 14.9ms\n",
            "Speed: 4.1ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 20.5ms\n",
            "Speed: 4.2ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 27.5ms\n",
            "Speed: 2.6ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 21.3ms\n",
            "Speed: 2.8ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.9ms\n",
            "Speed: 16.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 22.4ms\n",
            "Speed: 3.0ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 13.1ms\n",
            "Speed: 7.1ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 17.1ms\n",
            "Speed: 3.0ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.4ms\n",
            "Speed: 4.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 cars, 1 truck, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 14.9ms\n",
            "Speed: 4.4ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 15.1ms\n",
            "Speed: 6.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 20.6ms\n",
            "Speed: 2.8ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 3 trucks, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 16.7ms\n",
            "Speed: 8.6ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 12.4ms\n",
            "Speed: 2.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 21.9ms\n",
            "Speed: 2.7ms preprocess, 21.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 16.0ms\n",
            "Speed: 13.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 24.3ms\n",
            "Speed: 4.1ms preprocess, 24.3ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 19.8ms\n",
            "Speed: 2.7ms preprocess, 19.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 25.5ms\n",
            "Speed: 3.2ms preprocess, 25.5ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 18.2ms\n",
            "Speed: 5.9ms preprocess, 18.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 16.3ms\n",
            "Speed: 9.8ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 19.3ms\n",
            "Speed: 8.9ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 17.0ms\n",
            "Speed: 2.9ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 14.8ms\n",
            "Speed: 2.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 truck, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 2 trucks, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 2 trucks, 19.8ms\n",
            "Speed: 2.7ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 4.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 2 trucks, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 20.6ms\n",
            "Speed: 4.1ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.2ms\n",
            "Speed: 4.6ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 21.4ms\n",
            "Speed: 3.0ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 8.4ms\n",
            "Speed: 2.7ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.8ms\n",
            "Speed: 3.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.7ms\n",
            "Speed: 4.2ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 9.6ms\n",
            "Speed: 4.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25 cars, 2 trucks, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 1 truck, 17.6ms\n",
            "Speed: 2.8ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 14.1ms\n",
            "Speed: 4.1ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 1 truck, 19.3ms\n",
            "Speed: 6.5ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 15.2ms\n",
            "Speed: 2.7ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 2 trucks, 29.1ms\n",
            "Speed: 2.7ms preprocess, 29.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 22.1ms\n",
            "Speed: 2.9ms preprocess, 22.1ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 21.0ms\n",
            "Speed: 2.8ms preprocess, 21.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 16.1ms\n",
            "Speed: 2.9ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 26.2ms\n",
            "Speed: 2.8ms preprocess, 26.2ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 16.9ms\n",
            "Speed: 2.9ms preprocess, 16.9ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 19.9ms\n",
            "Speed: 2.9ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 19.2ms\n",
            "Speed: 2.8ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 31.8ms\n",
            "Speed: 2.7ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 15.7ms\n",
            "Speed: 6.6ms preprocess, 15.7ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 24.6ms\n",
            "Speed: 2.7ms preprocess, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 4 trucks, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 20.0ms\n",
            "Speed: 5.3ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 17.9ms\n",
            "Speed: 3.5ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 bus, 1 truck, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 bus, 1 truck, 23.1ms\n",
            "Speed: 2.7ms preprocess, 23.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 bus, 1 truck, 15.0ms\n",
            "Speed: 5.3ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 bus, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 bus, 1 truck, 14.6ms\n",
            "Speed: 3.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 bus, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 bus, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 1 truck, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 bus, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 1 truck, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 9.9ms\n",
            "Speed: 4.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 truck, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 26.8ms\n",
            "Speed: 3.0ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 19.3ms\n",
            "Speed: 2.7ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 1 truck, 19.8ms\n",
            "Speed: 2.7ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 18.6ms\n",
            "Speed: 2.6ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 22.8ms\n",
            "Speed: 2.8ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 25.4ms\n",
            "Speed: 2.8ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 15.3ms\n",
            "Speed: 6.0ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 24.3ms\n",
            "Speed: 2.8ms preprocess, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 18.0ms\n",
            "Speed: 2.8ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 28.1ms\n",
            "Speed: 2.8ms preprocess, 28.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 27.4ms\n",
            "Speed: 3.0ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 14.0ms\n",
            "Speed: 2.6ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 20.6ms\n",
            "Speed: 8.0ms preprocess, 20.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 23.9ms\n",
            "Speed: 2.9ms preprocess, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 28.1ms\n",
            "Speed: 2.8ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 28.6ms\n",
            "Speed: 2.7ms preprocess, 28.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 31.1ms\n",
            "Speed: 2.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 cars, 1 truck, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 28 cars, 1 truck, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 truck, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 13.5ms\n",
            "Speed: 3.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 truck, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 19.2ms\n",
            "Speed: 2.9ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 2 trucks, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 cars, 1 truck, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 truck, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 1 truck, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 bus, 2 trucks, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 12.7ms\n",
            "Speed: 2.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 24.1ms\n",
            "Speed: 2.8ms preprocess, 24.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 18.3ms\n",
            "Speed: 4.0ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 31.2ms\n",
            "Speed: 3.5ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 14.9ms\n",
            "Speed: 4.9ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 12.2ms\n",
            "Speed: 9.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 23.7ms\n",
            "Speed: 6.9ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 8.6ms\n",
            "Speed: 9.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 24.0ms\n",
            "Speed: 2.7ms preprocess, 24.0ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 25.4ms\n",
            "Speed: 2.6ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 30.9ms\n",
            "Speed: 2.7ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 28.1ms\n",
            "Speed: 2.6ms preprocess, 28.1ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 19.7ms\n",
            "Speed: 2.8ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 22.1ms\n",
            "Speed: 15.7ms preprocess, 22.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 14.1ms\n",
            "Speed: 7.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 19.5ms\n",
            "Speed: 2.8ms preprocess, 19.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 13.9ms\n",
            "Speed: 6.5ms preprocess, 13.9ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 10.6ms\n",
            "Speed: 6.2ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 18.6ms\n",
            "Speed: 5.5ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 21.9ms\n",
            "Speed: 7.7ms preprocess, 21.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 1 truck, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 22.0ms\n",
            "Speed: 2.7ms preprocess, 22.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 19.7ms\n",
            "Speed: 2.6ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 2 trucks, 17.1ms\n",
            "Speed: 4.7ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 18.3ms\n",
            "Speed: 3.2ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 2 trucks, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 22.5ms\n",
            "Speed: 9.8ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 19.6ms\n",
            "Speed: 9.0ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 21.9ms\n",
            "Speed: 2.6ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 16.1ms\n",
            "Speed: 11.1ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 28.4ms\n",
            "Speed: 13.6ms preprocess, 28.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 16.3ms\n",
            "Speed: 14.6ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 39.5ms\n",
            "Speed: 2.6ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 14.7ms\n",
            "Speed: 3.0ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 18.0ms\n",
            "Speed: 3.0ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 16.3ms\n",
            "Speed: 5.4ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 2 trucks, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 19.0ms\n",
            "Speed: 2.9ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 1 truck, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 truck, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 truck, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 2 trucks, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 2 trucks, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 truck, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 1 truck, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 14.6ms\n",
            "Speed: 4.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 3 trucks, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 2 trucks, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 bus, 3 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 15.5ms\n",
            "Speed: 2.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 bus, 3 trucks, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 21.6ms\n",
            "Speed: 2.8ms preprocess, 21.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 4 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 3 trucks, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 4 trucks, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 4 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 1 bus, 3 trucks, 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 3 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 3 trucks, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 2 trucks, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 3 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 3 trucks, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 22.4ms\n",
            "Speed: 2.7ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 2 trucks, 15.6ms\n",
            "Speed: 5.5ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 16.5ms\n",
            "Speed: 6.8ms preprocess, 16.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 17.2ms\n",
            "Speed: 2.8ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 15.3ms\n",
            "Speed: 8.8ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 14.9ms\n",
            "Speed: 3.2ms preprocess, 14.9ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 19.4ms\n",
            "Speed: 3.2ms preprocess, 19.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.2ms\n",
            "Speed: 3.7ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 1 truck, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 18.6ms\n",
            "Speed: 9.7ms preprocess, 18.6ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 24.3ms\n",
            "Speed: 2.8ms preprocess, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 1 bus, 3 trucks, 18.5ms\n",
            "Speed: 14.8ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 16.9ms\n",
            "Speed: 3.7ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 1 bus, 4 trucks, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 1 truck, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 3 trucks, 28.3ms\n",
            "Speed: 3.3ms preprocess, 28.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 11.0ms\n",
            "Speed: 5.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 3 trucks, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 18.9ms\n",
            "Speed: 9.3ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 trucks, 25.0ms\n",
            "Speed: 2.8ms preprocess, 25.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 3 trucks, 25.6ms\n",
            "Speed: 2.7ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 21.2ms\n",
            "Speed: 2.8ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 3 trucks, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 16.9ms\n",
            "Speed: 4.1ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 3 trucks, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 27.5ms\n",
            "Speed: 2.9ms preprocess, 27.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 3 trucks, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 4 trucks, 26.3ms\n",
            "Speed: 5.8ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 1 truck, 15.4ms\n",
            "Speed: 11.1ms preprocess, 15.4ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 4 trucks, 23.6ms\n",
            "Speed: 2.8ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 4 trucks, 15.4ms\n",
            "Speed: 4.0ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 truck, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 3 trucks, 18.8ms\n",
            "Speed: 7.3ms preprocess, 18.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 5 trucks, 30.3ms\n",
            "Speed: 3.0ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 5 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21 cars, 1 truck, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 6 trucks, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 5 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 4 trucks, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 4 trucks, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 truck, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 3 trucks, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 2 trucks, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 3 trucks, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 3 trucks, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 17.4ms\n",
            "Speed: 2.8ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 3 trucks, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 29.6ms\n",
            "Speed: 2.8ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 3 trucks, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 3 trucks, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 3 trucks, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 3 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 11.4ms\n",
            "Speed: 6.8ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 4 trucks, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 4 trucks, 14.8ms\n",
            "Speed: 2.8ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 2 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 4 trucks, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 4 trucks, 24.4ms\n",
            "Speed: 2.6ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 4 trucks, 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 4 trucks, 18.1ms\n",
            "Speed: 2.7ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25 cars, 2 trucks, 19.7ms\n",
            "Speed: 2.7ms preprocess, 19.7ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 3 trucks, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27 cars, 2 trucks, 16.7ms\n",
            "Speed: 2.7ms preprocess, 16.7ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 4 trucks, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 truck, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 4 trucks, 11.5ms\n",
            "Speed: 4.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 2 trucks, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 truck, 17.1ms\n",
            "Speed: 5.0ms preprocess, 17.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 4 trucks, 20.7ms\n",
            "Speed: 3.7ms preprocess, 20.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 1 truck, 18.4ms\n",
            "Speed: 9.5ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 19.6ms\n",
            "Speed: 2.6ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 17.6ms\n",
            "Speed: 2.7ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 3 trucks, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23 cars, 1 truck, 22.7ms\n",
            "Speed: 2.6ms preprocess, 22.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 3 trucks, 23.2ms\n",
            "Speed: 2.6ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 23.5ms\n",
            "Speed: 2.7ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 4 trucks, 25.5ms\n",
            "Speed: 2.6ms preprocess, 25.5ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 33.9ms\n",
            "Speed: 2.7ms preprocess, 33.9ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 23.4ms\n",
            "Speed: 3.7ms preprocess, 23.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 24.2ms\n",
            "Speed: 9.5ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 4 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 3 trucks, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 4 trucks, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 4 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 4 trucks, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17 cars, 4 trucks, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20 cars, 1 truck, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 4 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 1 truck, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16 cars, 5 trucks, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16 cars, 4 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14 cars, 4 trucks, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 2 trucks, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 16 cars, 4 trucks, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 15 cars, 4 trucks, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 1 truck, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 10.6ms\n",
            "Speed: 5.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 1 truck, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 2 trucks, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 2 trucks, 22.5ms\n",
            "Speed: 3.5ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18 cars, 3 trucks, 18.8ms\n",
            "Speed: 2.7ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 4 trucks, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 1 bus, 4 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 truck, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 4 trucks, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 truck, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 4 trucks, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 truck, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 3 trucks, 15.5ms\n",
            "Speed: 3.2ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 3 trucks, 18.6ms\n",
            "Speed: 3.0ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16 cars, 3 trucks, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 3 trucks, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16 cars, 3 trucks, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 3 trucks, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 15.2ms\n",
            "Speed: 3.3ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 2 trucks, 16.4ms\n",
            "Speed: 5.7ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 4 trucks, 20.2ms\n",
            "Speed: 3.1ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 4 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 2 trucks, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 2 trucks, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 1 truck, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 1 truck, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 2 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19 cars, 2 trucks, 9.6ms\n",
            "Speed: 10.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 19.6ms\n",
            "Speed: 2.7ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 1 truck, 26.7ms\n",
            "Speed: 8.2ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 4 trucks, 24.6ms\n",
            "Speed: 2.6ms preprocess, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24 cars, 2 trucks, 21.1ms\n",
            "Speed: 2.7ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 4 trucks, 24.9ms\n",
            "Speed: 2.6ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 12.8ms\n",
            "Speed: 4.1ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 15.0ms\n",
            "Speed: 9.6ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 25.5ms\n",
            "Speed: 5.0ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 19.2ms\n",
            "Speed: 4.9ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 19.8ms\n",
            "Speed: 2.7ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 19.6ms\n",
            "Speed: 5.8ms preprocess, 19.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 truck, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 16.5ms\n",
            "Speed: 7.6ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 20.5ms\n",
            "Speed: 2.6ms preprocess, 20.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.5ms\n",
            "Speed: 5.3ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20 cars, 2 trucks, 19.2ms\n",
            "Speed: 2.7ms preprocess, 19.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 30.9ms\n",
            "Speed: 2.8ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 28.6ms\n",
            "Speed: 2.5ms preprocess, 28.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 27.8ms\n",
            "Speed: 2.6ms preprocess, 27.8ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 24.9ms\n",
            "Speed: 10.0ms preprocess, 24.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 25.0ms\n",
            "Speed: 3.6ms preprocess, 25.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21 cars, 2 trucks, 15.7ms\n",
            "Speed: 5.3ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 4 trucks, 16.8ms\n",
            "Speed: 3.0ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25 cars, 2 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 4 trucks, 12.4ms\n",
            "Speed: 2.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 4 trucks, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 5 trucks, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.6ms\n",
            "Speed: 5.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 4 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 5 trucks, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 26.9ms\n",
            "Speed: 2.6ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 23.7ms\n",
            "Speed: 3.2ms preprocess, 23.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 2 trucks, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 20.8ms\n",
            "Speed: 3.0ms preprocess, 20.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 22.3ms\n",
            "Speed: 2.8ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 2 trucks, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 2 trucks, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 2 trucks, 18.1ms\n",
            "Speed: 2.7ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 15.7ms\n",
            "Speed: 4.7ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 5 trucks, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 6 trucks, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 3 trucks, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 3 trucks, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 2 trucks, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 4 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 2 trucks, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 6 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 2 trucks, 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 6 trucks, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 6 trucks, 8.6ms\n",
            "Speed: 2.7ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 4 trucks, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 4 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 3 trucks, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.7ms\n",
            "Speed: 5.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 3 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 4 trucks, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 6 trucks, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 2 trucks, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 6 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 6 trucks, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 5 trucks, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 4 trucks, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 6 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 4 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 21.7ms\n",
            "Speed: 2.7ms preprocess, 21.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 4 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 5 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 1 bus, 3 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 3 trucks, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 3 trucks, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 23.7ms\n",
            "Speed: 2.7ms preprocess, 23.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 4 trucks, 11.7ms\n",
            "Speed: 7.4ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 5 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 cars, 3 trucks, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 cars, 5 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 7 trucks, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 8 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 8 trucks, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 6 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 6 trucks, 19.5ms\n",
            "Speed: 7.2ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 cars, 7 trucks, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 8 trucks, 23.1ms\n",
            "Speed: 2.8ms preprocess, 23.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 2 trucks, 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 8 trucks, 24.7ms\n",
            "Speed: 2.7ms preprocess, 24.7ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 4 trucks, 19.4ms\n",
            "Speed: 2.7ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 8 trucks, 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 22.4ms\n",
            "Speed: 2.7ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 7 trucks, 28.4ms\n",
            "Speed: 2.6ms preprocess, 28.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 23.1ms\n",
            "Speed: 2.6ms preprocess, 23.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 4 trucks, 22.7ms\n",
            "Speed: 2.8ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 7 trucks, 11.8ms\n",
            "Speed: 10.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 8.5ms\n",
            "Speed: 2.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 6 trucks, 18.8ms\n",
            "Speed: 2.6ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 8.5ms\n",
            "Speed: 2.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 28.0ms\n",
            "Speed: 2.8ms preprocess, 28.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 7 trucks, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 29.5ms\n",
            "Speed: 2.8ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 6 trucks, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 5 trucks, 12.8ms\n",
            "Speed: 4.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 2 trucks, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 5 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 18.1ms\n",
            "Speed: 3.5ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 2 trucks, 17.0ms\n",
            "Speed: 5.7ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 18.0ms\n",
            "Speed: 3.0ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 20.2ms\n",
            "Speed: 8.8ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 3 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 26.5ms\n",
            "Speed: 2.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 18.9ms\n",
            "Speed: 2.8ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 19.8ms\n",
            "Speed: 2.8ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 3 trucks, 30.7ms\n",
            "Speed: 2.5ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 26.9ms\n",
            "Speed: 2.8ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 34.1ms\n",
            "Speed: 2.7ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 4 trucks, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 20.8ms\n",
            "Speed: 3.3ms preprocess, 20.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 10.1ms\n",
            "Speed: 4.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 5 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 2 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 4 trucks, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 5 trucks, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 4 trucks, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 4 trucks, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 7 trucks, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 3 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 21.7ms\n",
            "Speed: 2.8ms preprocess, 21.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 6 trucks, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 3 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 7 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 7 trucks, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 3 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 5 trucks, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 3 trucks, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 3 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 17.8ms\n",
            "Speed: 2.8ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 4 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 6 trucks, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 6 trucks, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 4 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 11.1ms\n",
            "Speed: 2.8ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 5 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 3 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 5 trucks, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 8 trucks, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 3 trucks, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 8 trucks, 14.8ms\n",
            "Speed: 4.0ms preprocess, 14.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 23.3ms\n",
            "Speed: 2.6ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 4 trucks, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 cars, 4 trucks, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 5 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 5 trucks, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 cars, 3 trucks, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 4 trucks, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 3 trucks, 6.3ms\n",
            "Speed: 2.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 5 trucks, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 4 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 6 trucks, 23.9ms\n",
            "Speed: 3.2ms preprocess, 23.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 4 trucks, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 4 trucks, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 4 trucks, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 3 trucks, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 2 trucks, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 cars, 1 bus, 4 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 3 trucks, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 3 trucks, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 3 trucks, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 3 trucks, 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 bus, 2 trucks, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 2 trucks, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 cars, 4 trucks, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 cars, 3 trucks, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 cars, 1 bus, 3 trucks, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 4 trucks, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 3 trucks, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 1 bus, 4 trucks, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 cars, 1 bus, 3 trucks, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 cars, 1 bus, 4 trucks, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 cars, 5 trucks, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 cars, 1 bus, 4 trucks, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 cars, 4 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 3 trucks, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 6 trucks, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 cars, 1 bus, 3 trucks, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 cars, 7 trucks, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 cars, 1 bus, 3 trucks, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 cars, 4 trucks, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'bbox': [2196.237222178182, 1175.881141653325, 2788.2000331971217, 1758.2530143584318]}, 'license_plate': {'bbox': [2204.590576171875, 1178.4613037109375, 2781.532470703125, 1757.1610107421875], 'text': 'MU51VSU', 'bbox_score': 0.76050865650177, 'text_score': 0.18244288540562828}}\n",
            "{'car': {'bbox': [2188.581234067502, 1176.8325917856746, 2794.5779790421248, 1768.7623736964147]}, 'license_plate': {'bbox': [2206.314453125, 1190.301025390625, 2782.548828125, 1767.78564453125], 'text': 'MU51VSU', 'bbox_score': 0.77333003282547, 'text_score': 0.21548974066351412}}\n",
            "{'car': {'bbox': [2193.018493606223, 1174.0383689880655, 2809.2789991995646, 1773.5144481276739]}, 'license_plate': {'bbox': [2208.2685546875, 1194.0675048828125, 2784.7099609375, 1771.66845703125], 'text': 'NI51TSU', 'bbox_score': 0.7716212868690491, 'text_score': 0.017520222511313892}}\n",
            "{'car': {'bbox': [719.3434292763964, 1413.5827855835132, 1421.7869544772861, 2058.1886679289646]}, 'license_plate': {'bbox': [730.8012084960938, 1420.455810546875, 1414.4058837890625, 2047.3963623046875], 'text': 'NA13NRU', 'bbox_score': 0.7495024800300598, 'text_score': 0.3489386512895862}}\n",
            "{'car': {'bbox': [710.6084000912356, 1419.0849190664196, 1416.7057138714104, 2066.5473393174243]}, 'license_plate': {'bbox': [723.6265869140625, 1427.3099365234375, 1407.66259765625, 2055.22265625], 'text': 'NA13NRU', 'bbox_score': 0.8201752305030823, 'text_score': 0.5703097412078216}}\n",
            "{'car': {'bbox': [701.9185328404997, 1423.5520553485387, 1410.7907396927621, 2073.110536009407]}, 'license_plate': {'bbox': [720.5459594726562, 1428.6314697265625, 1406.2445068359375, 2061.405029296875], 'text': 'NA13MRU', 'bbox_score': 0.8075827956199646, 'text_score': 0.20194070014971394}}\n",
            "{'car': {'bbox': [698.1074951372647, 1430.8680769297373, 1408.537063122788, 2082.0219661998754]}, 'license_plate': {'bbox': [714.267578125, 1436.81494140625, 1398.695556640625, 2078.034423828125], 'text': 'NA13NRU', 'bbox_score': 0.8091662526130676, 'text_score': 0.18824506007670483}}\n",
            "{'car': {'bbox': [693.6689456523626, 1439.9993230903233, 1407.016913168488, 2092.135713454129]}, 'license_plate': {'bbox': [711.2514038085938, 1445.131591796875, 1398.1358642578125, 2086.8115234375], 'text': 'MA13NRU', 'bbox_score': 0.8122300505638123, 'text_score': 0.5853605594883149}}\n",
            "{'car': {'bbox': [2199.8308257916938, 1245.488080128287, 2825.079572647713, 1856.5839476096935]}, 'license_plate': {'bbox': [2207.943603515625, 1246.55029296875, 2810.58837890625, 1854.8310546875], 'text': 'ND51YSU', 'bbox_score': 0.6606231927871704, 'text_score': 0.47021510133361705}}\n",
            "{'car': {'bbox': [669.5854288397118, 1491.0206490780556, 1394.0744554807761, 2143.5323950671045]}, 'license_plate': {'bbox': [680.7294921875, 1491.8291015625, 1388.0970458984375, 2141.4052734375], 'text': 'NA13NRU', 'bbox_score': 0.7050228118896484, 'text_score': 0.32179792008157265}}\n",
            "{'car': {'bbox': [666.3378667157343, 1496.8746891700678, 1392.7448654907907, 2148.6519792830964]}, 'license_plate': {'bbox': [676.9560546875, 1500.0003662109375, 1383.48828125, 2141.828125], 'text': 'NA13NRU', 'bbox_score': 0.6626110076904297, 'text_score': 0.2509711694595019}}\n",
            "{'car': {'bbox': [660.3425105118324, 1506.1707486797113, 1388.3616843397642, 2153.3482433054014]}, 'license_plate': {'bbox': [672.272705078125, 1515.1043701171875, 1385.1396484375, 2150.3955078125], 'text': 'NA13NRU', 'bbox_score': 0.7222311496734619, 'text_score': 0.2511019295391187}}\n",
            "{'car': {'bbox': [652.4760033266446, 1515.671414397119, 1383.4699076389932, 2156.1545345983823]}, 'license_plate': {'bbox': [666.295654296875, 1520.43701171875, 1382.6673583984375, 2150.4072265625], 'text': 'NA13MRU', 'bbox_score': 0.7268315553665161, 'text_score': 0.867600660956468}}\n",
            "{'car': {'bbox': [2221.117976130564, 1369.7065894342907, 2899.3735809843947, 2045.8264001908722]}, 'license_plate': {'bbox': [2226.692138671875, 1377.549560546875, 2880.30810546875, 2040.67041015625], 'text': 'MT51VSU', 'bbox_score': 0.8379618525505066, 'text_score': 0.15198052434216702}}\n",
            "{'car': {'bbox': [979.0731918738043, 1366.1687148924675, 1685.3071240896907, 1907.3951869866382]}, 'license_plate': {'bbox': [981.5712890625, 1370.219970703125, 1679.3583984375, 1906.45458984375], 'text': 'GX15OGJ', 'bbox_score': 0.8510580658912659, 'text_score': 0.3742800968795535}}\n",
            "{'car': {'bbox': [976.5982888266209, 1367.575472455167, 1686.8702048662085, 1910.3288003343082]}, 'license_plate': {'bbox': [981.2411499023438, 1371.1005859375, 1683.673583984375, 1909.5780029296875], 'text': 'GX15OGJ', 'bbox_score': 0.8526021242141724, 'text_score': 0.44488690232349015}}\n",
            "{'car': {'bbox': [868.0026481718274, 1558.485152524671, 1646.1886219352145, 2147.2429549195886]}, 'license_plate': {'bbox': [878.4296264648438, 1565.502197265625, 1638.396484375, 2145.361572265625], 'text': 'GX15OGJ', 'bbox_score': 0.8393017649650574, 'text_score': 0.3434886138673561}}\n",
            "{'car': {'bbox': [865.0535577231544, 1563.095093185365, 1645.1811367135974, 2150.5967025449004]}, 'license_plate': {'bbox': [876.7864379882812, 1568.8466796875, 1636.83642578125, 2145.26416015625], 'text': 'GY15OGJ', 'bbox_score': 0.848442018032074, 'text_score': 0.35739172870383795}}\n",
            "{'car': {'bbox': [862.8777894935229, 1570.105300374309, 1645.6338918524857, 2153.766860757491]}, 'license_plate': {'bbox': [867.788818359375, 1581.293701171875, 1644.094482421875, 2145.299560546875], 'text': 'GY15OGJ', 'bbox_score': 0.8240445852279663, 'text_score': 0.4788828461523207}}\n",
            "{'car': {'bbox': [857.1335719094661, 1581.0037917549791, 1644.8516857262578, 2156.982745934634]}, 'license_plate': {'bbox': [857.171630859375, 1592.4443359375, 1640.50634765625, 2145.825927734375], 'text': 'GY15OGJ', 'bbox_score': 0.8428420424461365, 'text_score': 0.22937107410268964}}\n",
            "{'car': {'bbox': [2240.4249931832874, 1605.6156180879439, 2960.7593719515535, 2159.428700015234]}, 'license_plate': {'bbox': [2248.9755859375, 1607.447021484375, 2956.64697265625, 2139.046875], 'text': 'LM13VCV', 'bbox_score': 0.7962828874588013, 'text_score': 0.29846747557236664}}\n",
            "{'car': {'bbox': [851.6799139739451, 1588.0274795098906, 1642.7032135006648, 2157.1206144334824]}, 'license_plate': {'bbox': [854.0042724609375, 1596.1981201171875, 1630.263671875, 2145.3623046875], 'text': 'GY15OGJ', 'bbox_score': 0.8621332049369812, 'text_score': 0.5609699011727313}}\n",
            "{'car': {'bbox': [2238.8889218194495, 1609.914855931474, 2962.6647434332504, 2160.044022508251]}, 'license_plate': {'bbox': [2255.297607421875, 1611.5885009765625, 2955.233642578125, 2133.037109375], 'text': 'LM13VCV', 'bbox_score': 0.8209367394447327, 'text_score': 0.22590128587419905}}\n",
            "{'car': {'bbox': [2240.9379464648273, 1613.8441950512852, 2968.2364821142082, 2156.877790723362]}, 'license_plate': {'bbox': [2260.194580078125, 1621.00634765625, 2957.71142578125, 2137.44873046875], 'text': 'LM13VCV', 'bbox_score': 0.824188768863678, 'text_score': 0.5360555033929836}}\n",
            "{'car': {'bbox': [2241.371159158959, 1618.2295816458563, 2973.6091204591357, 2154.4143250195452]}, 'license_plate': {'bbox': [2258.8916015625, 1623.8734130859375, 2966.237548828125, 2133.16015625], 'text': 'LM13VCV', 'bbox_score': 0.819521963596344, 'text_score': 0.2908767132496985}}\n",
            "{'car': {'bbox': [2244.1354985146163, 1623.081345984286, 2978.9247358007988, 2152.378514478606]}, 'license_plate': {'bbox': [2261.2001953125, 1625.1478271484375, 2967.638671875, 2139.8984375], 'text': 'LH13VCV', 'bbox_score': 0.8439093232154846, 'text_score': 0.6765575685116265}}\n",
            "{'car': {'bbox': [2244.4862175941334, 1637.2915632190711, 2984.7276962125106, 2151.6226240805086]}, 'license_plate': {'bbox': [2246.1630859375, 1647.2618408203125, 2972.919921875, 2140.93896484375], 'text': 'LM13VCV', 'bbox_score': 0.8764024376869202, 'text_score': 0.21096101733578837}}\n",
            "{'car': {'bbox': [2244.0414135612446, 1643.6138238944118, 2985.3826973978094, 2152.254918217744]}, 'license_plate': {'bbox': [2245.80517578125, 1653.0400390625, 2974.251953125, 2145.265625], 'text': 'LM13VCV', 'bbox_score': 0.8807520270347595, 'text_score': 0.43049429875346806}}\n",
            "{'car': {'bbox': [2242.356867855686, 1651.7084147264802, 2986.2619218514083, 2156.002844844969]}, 'license_plate': {'bbox': [2250.81201171875, 1660.872802734375, 2980.381591796875, 2152.948974609375], 'text': 'LM13VCV', 'bbox_score': 0.8762629628181458, 'text_score': 0.3557263268001803}}\n",
            "{'car': {'bbox': [2243.202320772314, 1660.4719968832728, 2989.0898420346975, 2159.4040322073206]}, 'license_plate': {'bbox': [2253.41796875, 1669.6640625, 2983.93408203125, 2157.36474609375], 'text': 'LN13VCV', 'bbox_score': 0.8809704184532166, 'text_score': 0.5065844055831819}}\n",
            "{'car': {'bbox': [2245.322054447691, 1667.9505890520695, 2990.5724749624815, 2162.272955141584]}, 'license_plate': {'bbox': [2251.25537109375, 1673.7960205078125, 2987.044189453125, 2157.3466796875], 'text': 'LM13VCV', 'bbox_score': 0.8850232362747192, 'text_score': 0.3443982944527061}}\n",
            "{'car': {'bbox': [2248.690580204632, 1674.8519583062896, 2995.3341743462843, 2161.574159187412]}, 'license_plate': {'bbox': [2256.97314453125, 1686.6163330078125, 2992.59912109375, 2156.95263671875], 'text': 'LM13VCV', 'bbox_score': 0.8908295035362244, 'text_score': 0.40935378448439136}}\n",
            "{'car': {'bbox': [2250.865007573654, 1682.6141927013452, 2996.963750707958, 2161.129206203075]}, 'license_plate': {'bbox': [2260.3662109375, 1691.621826171875, 2995.6044921875, 2157.2763671875], 'text': 'LM13VCV', 'bbox_score': 0.9096947312355042, 'text_score': 0.3374505868101273}}\n",
            "{'car': {'bbox': [2253.7636603841024, 1690.0530312190642, 2998.597164540845, 2162.949300342562]}, 'license_plate': {'bbox': [2261.015625, 1694.8963623046875, 2997.952880859375, 2157.41845703125], 'text': 'LM13VCV', 'bbox_score': 0.8994095921516418, 'text_score': 0.3581172909903939}}\n",
            "{'car': {'bbox': [1018.227793549822, 1220.8783144286754, 1567.7989720386395, 1694.3054963334944]}, 'license_plate': {'bbox': [1024.4267578125, 1223.757568359375, 1561.5281982421875, 1693.775146484375], 'text': 'KH05ZZK', 'bbox_score': 0.7354919910430908, 'text_score': 0.23620467106160523}}\n",
            "{'car': {'bbox': [2103.443921170643, 1585.396562056962, 2849.574953628906, 2157.783574778739]}, 'license_plate': {'bbox': [2117.05615234375, 1587.810791015625, 2826.40087890625, 2157.775390625], 'text': 'AP05JEQ', 'bbox_score': 0.877208948135376, 'text_score': 0.20672900582018777}}\n",
            "{'car': {'bbox': [2110.174061267191, 1595.8401427436897, 2860.3059385691795, 2156.1195610451596]}, 'license_plate': {'bbox': [2118.258544921875, 1596.86376953125, 2833.905029296875, 2155.86865234375], 'text': 'AP05JEQ', 'bbox_score': 0.8345640301704407, 'text_score': 0.4163862166188171}}\n",
            "{'car': {'bbox': [741.5734073070005, 1618.6247569566947, 1440.312085159491, 2155.742030500087]}, 'license_plate': {'bbox': [750.9663696289062, 1622.43896484375, 1430.066162109375, 2152.119873046875], 'text': 'KH05ZZK', 'bbox_score': 0.8598181009292603, 'text_score': 0.4224711176019827}}\n",
            "{'car': {'bbox': [732.4133498471549, 1624.3708520864427, 1440.0289098623068, 2154.949691727938]}, 'license_plate': {'bbox': [743.1688232421875, 1633.2139892578125, 1430.810546875, 2152.54248046875], 'text': 'KI05ZIM', 'bbox_score': 0.8443226218223572, 'text_score': 0.05574816707380332}}\n",
            "{'car': {'bbox': [816.7867057665223, 1627.3184233736772, 1510.0023243196772, 2158.8217829591104]}, 'license_plate': {'bbox': [822.2653198242188, 1636.332763671875, 1507.925048828125, 2151.072021484375], 'text': 'FJ14ZHY', 'bbox_score': 0.8857534527778625, 'text_score': 0.3381186510113433}}\n",
            "{'car': {'bbox': [812.3937396710573, 1634.1086480131946, 1508.3218090380349, 2161.8329522071394]}, 'license_plate': {'bbox': [824.2156982421875, 1638.7540283203125, 1507.5950927734375, 2151.30615234375], 'text': 'FJ14ZHY', 'bbox_score': 0.885672390460968, 'text_score': 0.3931792828264329}}\n",
            "{'car': {'bbox': [2371.3922334394815, 1354.8516818045819, 3011.9741381071085, 1939.1193940590783]}, 'license_plate': {'bbox': [2373.1875, 1360.617919921875, 3008.432373046875, 1938.9345703125], 'text': 'EY61NBG', 'bbox_score': 0.8227862119674683, 'text_score': 0.48721846740542746}}\n",
            "{'car': {'bbox': [2267.391278370517, 1104.6679525324198, 3142.412883986625, 2148.5153905399065]}, 'license_plate': {'bbox': [2299.65673828125, 1109.0123291015625, 3112.883056640625, 2145.15673828125], 'text': 'BG65USJ', 'bbox_score': 0.5619732141494751, 'text_score': 0.8890389885581746}}\n",
            "{'car': {'bbox': [1003.7355016985522, 1203.3846052606802, 1618.662493987094, 1764.295673521596]}, 'license_plate': {'bbox': [1005.943359375, 1204.517578125, 1613.2239990234375, 1763.237548828125], 'text': 'AK64DMC', 'bbox_score': 0.8783890008926392, 'text_score': 0.28365004469706123}}\n",
            "{'car': {'bbox': [934.7767383011718, 1280.8608956236353, 1572.726578548924, 1875.5841225996173]}, 'license_plate': {'bbox': [942.4881591796875, 1283.844970703125, 1572.0010986328125, 1872.3818359375], 'text': 'AK64DMV', 'bbox_score': 0.8462043404579163, 'text_score': 0.47307256722565677}}\n",
            "{'car': {'bbox': [899.8681588503312, 1323.4597962401008, 1560.5456188485316, 1934.542009128295]}, 'license_plate': {'bbox': [912.3953247070312, 1327.1824951171875, 1559.503662109375, 1928.80810546875], 'text': 'AK64DMV', 'bbox_score': 0.8639715313911438, 'text_score': 0.9151293075424377}}\n",
            "{'car': {'bbox': [897.0875256959607, 1326.5235081183298, 1559.756571013539, 1938.7474375449444]}, 'license_plate': {'bbox': [913.02978515625, 1330.1434326171875, 1554.982177734375, 1937.9208984375], 'text': 'AK64DMV', 'bbox_score': 0.8456189632415771, 'text_score': 0.48259336266430436}}\n",
            "{'car': {'bbox': [3006.8949175722346, 990.623028939474, 3511.924609754872, 1400.8394635514082]}, 'license_plate': {'bbox': [3008.615478515625, 996.8003540039062, 3503.5224609375, 1399.2066650390625], 'text': 'GI67HIJ', 'bbox_score': 0.8217107057571411, 'text_score': 0.09215910216950825}}\n",
            "{'car': {'bbox': [885.2590748419732, 1344.6022580713632, 1557.3312737309518, 1967.0381280532563]}, 'license_plate': {'bbox': [902.3908081054688, 1346.2041015625, 1553.594970703125, 1958.9482421875], 'text': 'AK64DMV', 'bbox_score': 0.8142387866973877, 'text_score': 0.6832848436593782}}\n",
            "{'car': {'bbox': [3033.2050479562577, 1004.154520655529, 3557.691817139388, 1437.8009029905463]}, 'license_plate': {'bbox': [3034.365234375, 1017.309814453125, 3551.126953125, 1437.27734375], 'text': 'DL02HJJ', 'bbox_score': 0.7385286092758179, 'text_score': 0.047554680809025654}}\n",
            "{'car': {'bbox': [2332.249838617474, 1347.2677667535, 2923.674075967416, 1874.6360197053432]}, 'license_plate': {'bbox': [2333.657958984375, 1353.6463623046875, 2922.492919921875, 1872.1014404296875], 'text': 'EF10DZT', 'bbox_score': 0.8343045711517334, 'text_score': 0.374864541473826}}\n",
            "{'car': {'bbox': [755.4924204740287, 1579.9674639780774, 1510.0328103757815, 2157.5076472776022]}, 'license_plate': {'bbox': [756.8755493164062, 1580.2005615234375, 1506.3116455078125, 2154.32177734375], 'text': 'AK64DMV', 'bbox_score': 0.8846904039382935, 'text_score': 0.8311372092275991}}\n",
            "{'car': {'bbox': [3241.539407507227, 1249.1933052197624, 3845.7991374373505, 1761.7974191687576]}, 'license_plate': {'bbox': [3252.1298828125, 1262.86474609375, 3836.56884765625, 1754.49853515625], 'text': 'OU62HYJ', 'bbox_score': 0.8368024230003357, 'text_score': 0.3969087653569273}}\n",
            "{'car': {'bbox': [3244.14468653344, 1254.8481182922742, 3844.975858011927, 1762.4311380765912]}, 'license_plate': {'bbox': [3254.260986328125, 1269.958984375, 3836.967041015625, 1757.4210205078125], 'text': 'OU62HYJ', 'bbox_score': 0.851585865020752, 'text_score': 0.32173456674208306}}\n",
            "{'car': {'bbox': [3257.3020878511256, 1262.9552575065832, 3845.8340765362304, 1778.709560244581]}, 'license_plate': {'bbox': [3265.69775390625, 1271.2196044921875, 3839.13720703125, 1778.693115234375], 'text': 'OU62HIJ', 'bbox_score': 0.7801106572151184, 'text_score': 0.3132018483228674}}\n",
            "{'car': {'bbox': [2338.030560065818, 1664.225644604906, 3068.0903961320932, 2160.0838236769014]}, 'license_plate': {'bbox': [2348.781005859375, 1671.7265625, 3055.051025390625, 2160.0], 'text': 'EF10DZT', 'bbox_score': 0.8697121739387512, 'text_score': 0.6019129030942673}}\n",
            "{'car': {'bbox': [3341.8198075206137, 1360.752258691649, 3844.8866469472605, 1923.6912728841369]}, 'license_plate': {'bbox': [3362.741455078125, 1382.008056640625, 3837.712646484375, 1920.51904296875], 'text': 'UU62HLJ', 'bbox_score': 0.8011155128479004, 'text_score': 0.16473095724214964}}\n",
            "{'car': {'bbox': [2258.2853916285794, 994.6219298210643, 2677.344474499768, 1371.1802612443182]}, 'license_plate': {'bbox': [2261.818115234375, 1001.4699096679688, 2676.339599609375, 1368.679443359375], 'text': 'SJ25EFD', 'bbox_score': 0.8252710700035095, 'text_score': 0.10978305539422752}}\n",
            "{'car': {'bbox': [3357.209498153801, 1365.4048423268923, 3845.604319998987, 1942.116422888931]}, 'license_plate': {'bbox': [3378.752197265625, 1415.9512939453125, 3837.74560546875, 1939.71240234375], 'text': 'OU52HRJ', 'bbox_score': 0.744543194770813, 'text_score': 0.06578521110016378}}\n",
            "{'car': {'bbox': [2229.07931602556, 1420.7900836771673, 2892.6144176382622, 1959.600186572498]}, 'license_plate': {'bbox': [2233.75537109375, 1426.7086181640625, 2883.164794921875, 1956.328857421875], 'text': 'AF65JKV', 'bbox_score': 0.8702222108840942, 'text_score': 0.7003367313389377}}\n",
            "{'car': {'bbox': [2232.0791305238904, 1426.2093738287451, 2900.843825984625, 1966.0098454117153]}, 'license_plate': {'bbox': [2236.616455078125, 1428.148681640625, 2886.85986328125, 1962.7789306640625], 'text': 'AR65JKV', 'bbox_score': 0.8772881031036377, 'text_score': 0.5134879511885216}}\n",
            "{'car': {'bbox': [799.1089515480461, 1573.6378091495014, 1515.5368353912622, 2157.534172379367]}, 'license_plate': {'bbox': [800.39794921875, 1581.3680419921875, 1496.852783203125, 2156.14404296875], 'text': 'KH06KSU', 'bbox_score': 0.8761517405509949, 'text_score': 0.0796490214632569}}\n",
            "{'car': {'bbox': [2303.219624838068, 1266.020522102243, 2833.396249606618, 1752.6348803429578]}, 'license_plate': {'bbox': [2305.718994140625, 1268.505615234375, 2832.31298828125, 1751.4169921875], 'text': 'GJ06EPD', 'bbox_score': 0.8783594965934753, 'text_score': 0.3619361457302099}}\n",
            "{'car': {'bbox': [767.520499076752, 1599.117768775099, 1506.8977030702122, 2157.6855039948546]}, 'license_plate': {'bbox': [784.1482543945312, 1604.3792724609375, 1501.21435546875, 2149.07177734375], 'text': 'KH06KSU', 'bbox_score': 0.8732813596725464, 'text_score': 0.30748047543104157}}\n",
            "{'car': {'bbox': [2299.1079919384983, 1320.101836408724, 2857.534176967727, 1825.7970847472207]}, 'license_plate': {'bbox': [2300.13720703125, 1322.288818359375, 2855.028076171875, 1823.8154296875], 'text': 'MJ06EPP', 'bbox_score': 0.9084824323654175, 'text_score': 0.07807219850858328}}\n",
            "{'car': {'bbox': [2305.5613683871234, 1346.4668935555032, 2871.909119501971, 1864.452266856597]}, 'license_plate': {'bbox': [2312.12451171875, 1350.7745361328125, 2865.987060546875, 1863.144287109375], 'text': 'GJ06EPD', 'bbox_score': 0.8879895210266113, 'text_score': 0.4250258531917133}}\n",
            "{'car': {'bbox': [2302.6789196926434, 1349.2501519765285, 2872.1502125097218, 1868.905682531671]}, 'license_plate': {'bbox': [2307.54443359375, 1351.962646484375, 2865.9384765625, 1865.18505859375], 'text': 'GJ06EPD', 'bbox_score': 0.8842893838882446, 'text_score': 0.1669287207036431}}\n",
            "{'car': {'bbox': [864.8052118966763, 1367.3958983813188, 1500.5852959976228, 1914.4274496640203]}, 'license_plate': {'bbox': [870.3729858398438, 1372.931396484375, 1500.158935546875, 1914.12744140625], 'text': 'LU15ZZC', 'bbox_score': 0.9003044962882996, 'text_score': 0.4671951670647168}}\n",
            "{'car': {'bbox': [1162.4121520795186, 743.7355766158139, 1778.8040025104176, 1524.8671722949557]}, 'license_plate': {'bbox': [1194.61767578125, 751.1500854492188, 1735.3251953125, 1510.54052734375], 'text': 'OI15ION', 'bbox_score': 0.2582337260246277, 'text_score': 0.09696224790959342}}\n",
            "{'car': {'bbox': [2307.898691333592, 1589.6642348930482, 2949.94991555696, 2150.669622357231]}, 'license_plate': {'bbox': [2318.25, 1600.989501953125, 2947.509521484375, 2146.836669921875], 'text': 'GJ06EPD', 'bbox_score': 0.9011784791946411, 'text_score': 0.4773420219781214}}\n",
            "{'car': {'bbox': [2309.189784546484, 1596.3946289917203, 2950.0860718970202, 2152.531477033721]}, 'license_plate': {'bbox': [2318.56884765625, 1604.906982421875, 2946.954345703125, 2146.21435546875], 'text': 'GJ06EPD', 'bbox_score': 0.9043370485305786, 'text_score': 0.4280828177777826}}\n",
            "{'car': {'bbox': [2313.157811460901, 1637.4715495442244, 2971.4243486539253, 2154.2106001378675]}, 'license_plate': {'bbox': [2318.3515625, 1643.41455078125, 2964.6669921875, 2154.083251953125], 'text': 'GJ06EPD', 'bbox_score': 0.8805329203605652, 'text_score': 0.5918517977652872}}\n",
            "{'car': {'bbox': [2311.29350711131, 1647.4757687554168, 2971.2060449117475, 2158.4331210048485]}, 'license_plate': {'bbox': [2321.06494140625, 1653.552978515625, 2965.6875, 2151.721435546875], 'text': 'GJ06EPD', 'bbox_score': 0.8994993567466736, 'text_score': 0.3129730636394467}}\n",
            "{'car': {'bbox': [635.1150067183795, 1570.62781626961, 1404.7263357635757, 2153.0011451681894]}, 'license_plate': {'bbox': [697.770263671875, 1573.689697265625, 1404.201171875, 2148.35400390625], 'text': 'LN15ZZC', 'bbox_score': 0.881698489189148, 'text_score': 0.6487398811232329}}\n",
            "{'car': {'bbox': [636.3404762400876, 1575.4229772831186, 1404.8275417578866, 2154.4802307323407]}, 'license_plate': {'bbox': [692.1142578125, 1581.4815673828125, 1397.7496337890625, 2146.09326171875], 'text': 'LN15ZZC', 'bbox_score': 0.9004570245742798, 'text_score': 0.2899853437721809}}\n",
            "{'car': {'bbox': [640.6221027952897, 1581.8848440366594, 1406.7481505000685, 2156.21143953016]}, 'license_plate': {'bbox': [690.6549072265625, 1587.56689453125, 1393.8773193359375, 2144.252197265625], 'text': 'LN15ZZC', 'bbox_score': 0.8824266195297241, 'text_score': 0.44493962334950027}}\n",
            "{'car': {'bbox': [630.8020082472447, 1586.9539252018596, 1402.521990721894, 2156.6480336247364]}, 'license_plate': {'bbox': [690.7442016601562, 1590.7342529296875, 1392.324462890625, 2142.91943359375], 'text': 'LM15ZZC', 'bbox_score': 0.8914611339569092, 'text_score': 0.7884329383170429}}\n",
            "{'car': {'bbox': [625.8143859666529, 1594.6533417295745, 1398.970213564194, 2157.188383871576]}, 'license_plate': {'bbox': [682.364013671875, 1600.20849609375, 1387.681396484375, 2141.95263671875], 'text': 'LN15ZZC', 'bbox_score': 0.8863670825958252, 'text_score': 0.69209699115224}}\n",
            "{'car': {'bbox': [614.4674857717016, 1601.196500181666, 1392.803493436187, 2158.234529981478]}, 'license_plate': {'bbox': [682.6640014648438, 1607.765625, 1389.728759765625, 2142.566162109375], 'text': 'LN15ZZC', 'bbox_score': 0.8536503911018372, 'text_score': 0.5128342235371346}}\n",
            "{'car': {'bbox': [634.8258254098359, 1610.8626791608833, 1400.5424591319281, 2159.4287108969993]}, 'license_plate': {'bbox': [675.9112548828125, 1617.65576171875, 1387.7117919921875, 2146.72802734375], 'text': 'LN15ZZC', 'bbox_score': 0.8757222294807434, 'text_score': 0.4278243902253154}}\n",
            "{'car': {'bbox': [633.9443311737834, 1615.7190196710437, 1395.693136934391, 2160.2271671179724]}, 'license_plate': {'bbox': [672.7967529296875, 1624.4140625, 1383.2803955078125, 2152.533935546875], 'text': 'LN15ZZC', 'bbox_score': 0.866755485534668, 'text_score': 0.6168753241996335}}\n",
            "{'car': {'bbox': [2292.203585253332, 1298.7992295984563, 2904.085656265524, 1779.1683417508566]}, 'license_plate': {'bbox': [2294.742431640625, 1302.205322265625, 2892.896240234375, 1775.4085693359375], 'text': 'DA07CLA', 'bbox_score': 0.8779428601264954, 'text_score': 0.3147478094016326}}\n",
            "{'car': {'bbox': [632.6196002239114, 1620.8351351097879, 1391.0049283777923, 2159.9071871846286]}, 'license_plate': {'bbox': [672.5402221679688, 1627.6673583984375, 1377.431396484375, 2149.95751953125], 'text': 'LN15ZZC', 'bbox_score': 0.8570054769515991, 'text_score': 0.6405953322428419}}\n",
            "{'car': {'bbox': [636.2437381994114, 1628.511068427098, 1390.3051954915106, 2160.230267203941]}, 'license_plate': {'bbox': [664.7095947265625, 1638.821044921875, 1378.6890869140625, 2147.0009765625], 'text': 'LM15ZZC', 'bbox_score': 0.8338838219642639, 'text_score': 0.3287335299795395}}\n",
            "{'car': {'bbox': [616.2291743426745, 1644.2937820933143, 1377.6919636956275, 2160.492334284152]}, 'license_plate': {'bbox': [666.6033325195312, 1651.537841796875, 1373.689453125, 2154.9921875], 'text': 'LN15ZZC', 'bbox_score': 0.8489142656326294, 'text_score': 0.5148162996064761}}\n",
            "{'car': {'bbox': [622.0795044701815, 1651.3772229419455, 1378.2948056622881, 2160.4360170765995]}, 'license_plate': {'bbox': [658.687255859375, 1658.209716796875, 1372.7554931640625, 2159.117431640625], 'text': 'LN15ZZC', 'bbox_score': 0.8690550923347473, 'text_score': 0.6440584312097013}}\n",
            "{'car': {'bbox': [1135.9027646227678, 843.9786101455987, 1793.9831428844236, 1691.735441436953]}, 'license_plate': {'bbox': [1169.3961181640625, 852.095947265625, 1771.4468994140625, 1686.3013916015625], 'text': 'OA41ACE', 'bbox_score': 0.28910723328590393, 'text_score': 0.2115903269485268}}\n",
            "{'car': {'bbox': [1118.9263475741755, 847.3386395126101, 1786.6001375419287, 1696.813117599763]}, 'license_plate': {'bbox': [1157.79931640625, 855.889892578125, 1766.9776611328125, 1694.158447265625], 'text': 'OG41GGE', 'bbox_score': 0.5393019318580627, 'text_score': 0.052270737578290406}}\n",
            "{'car': {'bbox': [2292.182553088739, 1337.0450011496434, 2917.217595223022, 1824.0374818803236]}, 'license_plate': {'bbox': [2292.328125, 1337.0859375, 2901.996826171875, 1819.635498046875], 'text': 'OA07CLX', 'bbox_score': 0.8725650310516357, 'text_score': 0.7072159678648033}}\n",
            "{'car': {'bbox': [2292.1673957914245, 1339.3523756757097, 2919.00090888621, 1829.2657771074435]}, 'license_plate': {'bbox': [2293.452880859375, 1342.0201416015625, 2908.422607421875, 1827.884765625], 'text': 'DA07CLX', 'bbox_score': 0.8663726449012756, 'text_score': 0.69103927164088}}\n",
            "{'car': {'bbox': [1115.258344438881, 857.3030424281646, 1802.131097465413, 1716.424841057903]}, 'license_plate': {'bbox': [1159.725830078125, 864.1045532226562, 1772.1815185546875, 1706.15966796875], 'text': 'DR41ACI', 'bbox_score': 0.6640596985816956, 'text_score': 0.15852358148027548}}\n",
            "{'car': {'bbox': [1104.1350390330044, 855.6347057846167, 1812.5561450962655, 1726.7510497249416]}, 'license_plate': {'bbox': [1153.5245361328125, 866.9434204101562, 1793.669921875, 1711.07470703125], 'text': 'OI15ION', 'bbox_score': 0.7017597556114197, 'text_score': 0.4030735937528167}}\n",
            "{'car': {'bbox': [2310.97064529344, 1478.7613452972794, 2994.7631010143227, 2016.7266472178474]}, 'license_plate': {'bbox': [2321.2109375, 1482.5595703125, 2990.2509765625, 2014.84716796875], 'text': 'DA07CLX', 'bbox_score': 0.8933877348899841, 'text_score': 0.47095429412001205}}\n",
            "{'car': {'bbox': [2346.9688122118796, 1608.890113766199, 3066.9276548278576, 2155.191116721298]}, 'license_plate': {'bbox': [2349.81201171875, 1612.294921875, 3062.6943359375, 2153.420654296875], 'text': 'DA07CLX', 'bbox_score': 0.8972150087356567, 'text_score': 0.31296864881453174}}\n",
            "{'car': {'bbox': [2352.918720645503, 1622.6764511749038, 3072.960891240385, 2155.1248799126433]}, 'license_plate': {'bbox': [2354.829345703125, 1624.3970947265625, 3068.031005859375, 2154.20849609375], 'text': 'DA07CLX', 'bbox_score': 0.8952548503875732, 'text_score': 0.6082477231602689}}\n",
            "{'car': {'bbox': [2356.410074466825, 1626.1685512575525, 3079.566767928897, 2153.623406219261]}, 'license_plate': {'bbox': [2356.973876953125, 1634.10107421875, 3072.8369140625, 2153.236572265625], 'text': 'DA07CLX', 'bbox_score': 0.8724959492683411, 'text_score': 0.6785619752802936}}\n",
            "{'car': {'bbox': [2110.314677458153, 1005.4066686102232, 2744.0824213576307, 1653.9133442058737]}, 'license_plate': {'bbox': [2115.118896484375, 1007.105712890625, 2713.674072265625, 1653.74560546875], 'text': 'EY09VVS', 'bbox_score': 0.6812261939048767, 'text_score': 0.5845452645109834}}\n",
            "{'car': {'bbox': [2106.738993596155, 1013.093906150111, 2733.0845309582314, 1673.254554258431]}, 'license_plate': {'bbox': [2117.23193359375, 1029.234375, 2701.704345703125, 1668.370849609375], 'text': 'EY09VOS', 'bbox_score': 0.7587924003601074, 'text_score': 0.3394415005744902}}\n",
            "{'car': {'bbox': [2368.13292462749, 1674.214860445164, 3113.281480315707, 2161.179727813154]}, 'license_plate': {'bbox': [2369.896728515625, 1684.724853515625, 3111.83740234375, 2159.11962890625], 'text': 'DA07CLX', 'bbox_score': 0.8825231194496155, 'text_score': 0.48472418244282867}}\n",
            "{'car': {'bbox': [2106.1037734466236, 1013.6035810397873, 2731.698909505395, 1675.168549811189]}, 'license_plate': {'bbox': [2114.05712890625, 1034.269775390625, 2705.08642578125, 1671.689208984375], 'text': 'EY06WIS', 'bbox_score': 0.635784387588501, 'text_score': 0.09885946597408135}}\n",
            "{'car': {'bbox': [2371.972359438132, 1681.5504592604814, 3119.3172582441866, 2162.16696873688]}, 'license_plate': {'bbox': [2372.03466796875, 1690.6988525390625, 3114.64599609375, 2157.76708984375], 'text': 'DA07CLX', 'bbox_score': 0.8755894899368286, 'text_score': 0.624062209609117}}\n",
            "{'car': {'bbox': [2107.0692764021505, 1021.4168452417906, 2748.1415625999643, 1702.6839066735397]}, 'license_plate': {'bbox': [2108.483642578125, 1059.189697265625, 2706.3310546875, 1701.320556640625], 'text': 'EY09VVS', 'bbox_score': 0.6108774542808533, 'text_score': 0.17385821544318356}}\n",
            "{'car': {'bbox': [2105.2955725183087, 1020.3510317021982, 2748.2655294860174, 1706.772130121516]}, 'license_plate': {'bbox': [2106.61572265625, 1064.719970703125, 2709.614501953125, 1700.9287109375], 'text': 'EJ09VVS', 'bbox_score': 0.5488803386688232, 'text_score': 0.15621237882896397}}\n",
            "{'car': {'bbox': [737.458336677576, 1256.2847564556298, 1695.5717391468906, 2146.3905745117486]}, 'license_plate': {'bbox': [742.5263061523438, 1257.301513671875, 1687.7442626953125, 2143.72900390625], 'text': 'OI15IOI', 'bbox_score': 0.44713497161865234, 'text_score': 0.18982312084653327}}\n",
            "{'car': {'bbox': [2158.1196914629973, 1355.7306213885224, 2959.816190347923, 2145.5306485140745]}, 'license_plate': {'bbox': [2160.268798828125, 1366.873046875, 2945.794189453125, 2145.494873046875], 'text': 'BP63LYH', 'bbox_score': 0.3794539272785187, 'text_score': 0.5402866969921513}}\n",
            "{'car': {'bbox': [2165.3000791979725, 1371.8293528866147, 2979.626157361336, 2145.2068271659286]}, 'license_plate': {'bbox': [2178.17578125, 1380.0830078125, 2966.540771484375, 2124.37744140625], 'text': 'BP63LMH', 'bbox_score': 0.2948645353317261, 'text_score': 0.2414936660940182}}\n",
            "{'car': {'bbox': [2166.191618558922, 1379.4348781555557, 2987.9179864779067, 2145.692826057736]}, 'license_plate': {'bbox': [2178.31494140625, 1391.509033203125, 2968.82958984375, 2130.5751953125], 'text': 'BP63LYH', 'bbox_score': 0.2995353043079376, 'text_score': 0.6707418851152378}}\n",
            "{'car': {'bbox': [2166.000003500488, 1383.8521814954524, 2998.34508332009, 2142.665605970564]}, 'license_plate': {'bbox': [2183.716064453125, 1396.53076171875, 2968.618408203125, 2080.908203125], 'text': 'BP63LYH', 'bbox_score': 0.3856819272041321, 'text_score': 0.8107278374378479}}\n",
            "{'car': {'bbox': [2168.257677733571, 1393.204947041857, 2999.785202719469, 2143.578902719357]}, 'license_plate': {'bbox': [2181.10595703125, 1401.147705078125, 2981.27880859375, 2143.13037109375], 'text': 'BP63LYH', 'bbox_score': 0.5340442061424255, 'text_score': 0.601012977632512}}\n",
            "{'car': {'bbox': [2172.9622979206265, 1397.122216129891, 3010.7102547289746, 2144.88693153448]}, 'license_plate': {'bbox': [2182.915283203125, 1408.107177734375, 2996.789794921875, 2136.2705078125], 'text': 'BP63LYH', 'bbox_score': 0.4760330021381378, 'text_score': 0.4110924200097985}}\n",
            "{'car': {'bbox': [2175.721280106376, 1402.5900399612365, 3020.709851637469, 2145.3757928323407]}, 'license_plate': {'bbox': [2197.7783203125, 1421.5108642578125, 3004.658203125, 2062.387939453125], 'text': 'AP63IYH', 'bbox_score': 0.5528424382209778, 'text_score': 0.11839215516751606}}\n",
            "{'car': {'bbox': [2183.4888281075855, 1424.6479497334872, 3051.509871480258, 2146.687442169279]}, 'license_plate': {'bbox': [2191.729248046875, 1433.72216796875, 3019.096435546875, 2120.421630859375], 'text': 'BP63LYH', 'bbox_score': 0.4032418429851532, 'text_score': 0.7326739224721837}}\n",
            "{'car': {'bbox': [2188.4090597655736, 1432.366907146567, 3057.4697150072802, 2149.4593538039358]}, 'license_plate': {'bbox': [2203.34619140625, 1441.29052734375, 3022.47509765625, 2112.18310546875], 'text': 'BP63LYH', 'bbox_score': 0.34997323155403137, 'text_score': 0.3770253465079488}}\n",
            "{'car': {'bbox': [2186.5918443028063, 1439.6449078124815, 3052.037622124372, 2150.005699174401]}, 'license_plate': {'bbox': [2204.57421875, 1451.332275390625, 3021.13720703125, 2112.40625], 'text': 'BP63LYH', 'bbox_score': 0.6376938223838806, 'text_score': 0.7136897982269959}}\n",
            "{'car': {'bbox': [2189.214715154977, 1459.5684308720886, 3049.259943280519, 2148.6999354127865]}, 'license_plate': {'bbox': [2193.44384765625, 1466.524169921875, 3024.5419921875, 2135.7763671875], 'text': 'BP63LYH', 'bbox_score': 0.6732938885688782, 'text_score': 0.5477387300251482}}\n",
            "{'car': {'bbox': [2188.8095353140134, 1465.887883758925, 3053.2118109637468, 2148.810359027728]}, 'license_plate': {'bbox': [2201.5166015625, 1471.9742431640625, 3040.44287109375, 2142.91943359375], 'text': 'BP63LYH', 'bbox_score': 0.6384760737419128, 'text_score': 0.5828647488170917}}\n",
            "{'car': {'bbox': [1050.3992107248137, 914.3682804394086, 1673.4252263365042, 1599.389556949535]}, 'license_plate': {'bbox': [1063.883544921875, 975.3724365234375, 1660.029052734375, 1443.9547119140625], 'text': 'NL64OGX', 'bbox_score': 0.5470234155654907, 'text_score': 0.46412388555999073}}\n",
            "{'car': {'bbox': [1029.2843958342742, 891.8157553520516, 1676.4149396738085, 1623.3861278495935]}, 'license_plate': {'bbox': [1048.981201171875, 1000.2423706054688, 1636.1744384765625, 1607.76953125], 'text': 'HL64OGX', 'bbox_score': 0.36168837547302246, 'text_score': 0.2363086796641666}}\n",
            "{'car': {'bbox': [1010.7693888389522, 903.9852087784634, 1649.5222018524655, 1648.1132457759995]}, 'license_plate': {'bbox': [1030.2052001953125, 1015.0057983398438, 1631.7264404296875, 1644.7174072265625], 'text': 'ML64OGN', 'bbox_score': 0.3917253911495209, 'text_score': 0.17985850292685093}}\n",
            "{'car': {'bbox': [996.2853121573737, 964.8135124074934, 1660.0621214980963, 1693.4118883580672]}, 'license_plate': {'bbox': [1013.3886108398438, 1035.419921875, 1627.680908203125, 1685.2760009765625], 'text': 'ML64OGX', 'bbox_score': 0.43719664216041565, 'text_score': 0.1562986224115558}}\n",
            "{'car': {'bbox': [980.6384549060808, 998.7685277686294, 1652.3296141243036, 1702.600746580921]}, 'license_plate': {'bbox': [1002.8724975585938, 1054.780029296875, 1626.458251953125, 1558.39599609375], 'text': 'NL64CGT', 'bbox_score': 0.45319613814353943, 'text_score': 0.0990266952731028}}\n",
            "{'car': {'bbox': [948.374097022479, 1062.5158003731206, 1643.8230456927618, 1749.3144598961887]}, 'license_plate': {'bbox': [968.498291015625, 1075.32275390625, 1612.76904296875, 1749.2889404296875], 'text': 'NL64OGX', 'bbox_score': 0.3929579257965088, 'text_score': 0.4278800670443775}}\n",
            "{'car': {'bbox': [947.0775997372194, 1069.8434175384598, 1642.1518515185585, 1751.2528729351009]}, 'license_plate': {'bbox': [964.477294921875, 1070.57373046875, 1610.8172607421875, 1746.87451171875], 'text': 'NL64OGX', 'bbox_score': 0.49663475155830383, 'text_score': 0.8442783956841531}}\n",
            "{'car': {'bbox': [930.7924756785674, 1088.4390302344323, 1634.846103746058, 1787.735346767402]}, 'license_plate': {'bbox': [945.7333374023438, 1104.0267333984375, 1610.36865234375, 1783.4564208984375], 'text': 'NL64OCX', 'bbox_score': 0.7304519414901733, 'text_score': 0.47967547986075654}}\n",
            "{'car': {'bbox': [670.8157805049307, 1383.3918355554947, 1526.550459861702, 2151.2821817592435]}, 'license_plate': {'bbox': [726.277587890625, 1388.967529296875, 1514.4296875, 2143.6689453125], 'text': 'NL64OGX', 'bbox_score': 0.5658287405967712, 'text_score': 0.18133822241481706}}\n",
            "{'car': {'bbox': [662.140592652238, 1414.39951412635, 1510.1460500809308, 2149.066494251556]}, 'license_plate': {'bbox': [710.184814453125, 1426.760498046875, 1504.656005859375, 2097.72119140625], 'text': 'NL64OGY', 'bbox_score': 0.48793360590934753, 'text_score': 0.6550921497251196}}\n",
            "{'car': {'bbox': [660.9151066025461, 1419.2994797784663, 1508.1060894119705, 2148.919122042653]}, 'license_plate': {'bbox': [711.492431640625, 1430.77783203125, 1507.78466796875, 2067.880859375], 'text': 'MI64NCY', 'bbox_score': 0.39595845341682434, 'text_score': 0.260954277801606}}\n",
            "{'car': {'bbox': [657.3842682333257, 1423.3735415811375, 1506.6236961312297, 2148.959242258227]}, 'license_plate': {'bbox': [698.8375854492188, 1432.7144775390625, 1504.44482421875, 2139.245361328125], 'text': 'NL64OGY', 'bbox_score': 0.44168755412101746, 'text_score': 0.7625863468354181}}\n",
            "{'car': {'bbox': [649.3395877622814, 1457.3588998170017, 1511.4862047404154, 2150.29770263221]}, 'license_plate': {'bbox': [680.8986206054688, 1459.4278564453125, 1508.6055908203125, 2147.731201171875], 'text': 'ML64OGY', 'bbox_score': 0.6030884385108948, 'text_score': 0.20718248091488486}}\n",
            "{'car': {'bbox': [632.5580758263425, 1464.9596576567221, 1504.140821663775, 2151.208714241151]}, 'license_plate': {'bbox': [665.3314819335938, 1472.2467041015625, 1497.209716796875, 2145.0849609375], 'text': 'NL64OGI', 'bbox_score': 0.47151264548301697, 'text_score': 0.13148971043716884}}\n",
            "{'car': {'bbox': [633.8866589156594, 1473.2820106739023, 1504.7150140927863, 2151.334084383003]}, 'license_plate': {'bbox': [667.8040771484375, 1475.3880615234375, 1497.953857421875, 2142.49609375], 'text': 'NI54OGY', 'bbox_score': 0.5654410123825073, 'text_score': 0.1363769246810134}}\n",
            "{'car': {'bbox': [1047.6142221798327, 1023.1271105024907, 1568.255529940287, 1519.730673541756]}, 'license_plate': {'bbox': [1052.481689453125, 1027.247314453125, 1564.778564453125, 1516.6827392578125], 'text': 'CE61LYL', 'bbox_score': 0.776662290096283, 'text_score': 0.3171774140842165}}\n",
            "{'car': {'bbox': [745.8648056663951, 1417.2279234495318, 1461.3916733305282, 2062.1835926337503]}, 'license_plate': {'bbox': [785.218017578125, 1424.493408203125, 1458.38720703125, 2055.66162109375], 'text': 'CE61MYL', 'bbox_score': 0.7568051218986511, 'text_score': 0.5176139793324923}}\n",
            "{'car': {'bbox': [751.5115312656379, 1420.9850461140713, 1464.130791633128, 2065.609119685109]}, 'license_plate': {'bbox': [781.66552734375, 1429.35302734375, 1459.06201171875, 2063.66943359375], 'text': 'CE61CYL', 'bbox_score': 0.7421208620071411, 'text_score': 0.30462520872803284}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 add_missing_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDpr89oI4zH",
        "outputId": "59ec828c-9c07-4bbc-c2a4-bb9fc6570670"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['207', '209'] 1\n",
            "['8', '9', '10', '11', '12', '19', '20', '21', '23'] 3\n",
            "['3', '5', '6', '18', '43'] 5\n",
            "['93', '94', '123', '124', '125', '126', '127'] 6\n",
            "['166', '239', '240'] 8\n",
            "['294', '295'] 16\n",
            "['126', '127', '128', '129', '130', '132', '133', '134', '135', '136', '137', '138', '139'] 34\n",
            "['309'] 299\n",
            "['662', '663'] 319\n",
            "['511', '533', '544', '545', '549', '597'] 345\n",
            "['653', '758', '773', '780', '781', '828', '829', '836', '837'] 366\n",
            "['549', '559', '624', '625', '629', '650', '653'] 385\n",
            "['458'] 591\n",
            "['859', '868', '869', '900', '923', '926', '927', '935', '936'] 604\n",
            "['572', '632'] 614\n",
            "['756', '760'] 657\n",
            "['810', '850', '851', '852', '853', '854', '855', '857', '858', '859', '860', '862', '863'] 784\n",
            "['865', '867', '870'] 911\n",
            "['819'] 919\n",
            "['872'] 993\n",
            "['930', '934', '935', '942', '943'] 1008\n",
            "['1163', '1167', '1168', '1169', '1171', '1172', '1173', '1177', '1178', '1179', '1182', '1183'] 1016\n",
            "['975'] 1098\n",
            "['1601', '1714', '1715'] 1469\n",
            "['1309', '1318', '1322', '1329', '1332'] 1471\n",
            "['1341', '1342', '1349'] 1582\n",
            "['1410', '1416', '1417', '1418', '1423', '1424', '1425'] 1655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 visualize.py"
      ],
      "metadata": {
        "id": "rRdscIjwOj-P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qVpY_yGQt2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}